{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2c242b06-1e1c-442f-a317-9b174c0cdf4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install streamlit yt-dlp python-dotenv requests pyngrok\n",
    "# !ngrok config add-authtoken 1dNsR0kkJxjfxj6zJUGXqOtTXIX_3aRKjTGdN8ZnUArHKKZbz\n",
    "# !xcode-select --install\n",
    "# !pip install watchdog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5b5e9426-6fd8-4201-843a-66dbc7954724",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyngrok import ngrok\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "NGROK_AUTH = os.getenv(\"NGROK_AUTH\")\n",
    "ngrok.set_auth_token(NGROK_AUTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "76f1c984-37a3-4bf2-90b8-3a0cd3c3a3d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d3c8f6494db4c8f86f3eb1e4d5971d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='YouTube URL:', layout=Layout(width='500px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a56a19f651974713b106e8d71277098b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Submit', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4b042a21a3f4f82ac68162c9a2424ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4af6e847de2a4a58b86761e1c93a6492",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML\n",
    "import yt_dlp\n",
    "import glob\n",
    "import os\n",
    "from ipywidgets import Layout\n",
    "import requests\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from urllib.parse import urlparse, parse_qs\n",
    "from requests.adapters import HTTPAdapter\n",
    "from requests.packages.urllib3.util.retry import Retry\n",
    "\n",
    "def get_youtube_id(url):\n",
    "    query = urlparse(url)\n",
    "    if query.hostname == 'youtu.be':\n",
    "        return query.path[1:]\n",
    "    if query.hostname in ('www.youtube.com', 'youtube.com'):\n",
    "        if query.path == '/watch':\n",
    "            p = parse_qs(query.query)\n",
    "            return p['v'][0]\n",
    "        if query.path[:7] == '/embed/':\n",
    "            return query.path.split('/')[2]\n",
    "        if query.path[:3] == '/v/':\n",
    "            return query.path.split('/')[2]\n",
    "    return None\n",
    "\n",
    "def download_video(url):\n",
    "    video_id = get_youtube_id(url)\n",
    "    if not video_id:\n",
    "        raise ValueError(\"Invalid YouTube URL\")\n",
    "    \n",
    "    ydl_opts = {\n",
    "        'format': 'bestvideo+bestaudio/best',\n",
    "        'outtmpl': f'{video_id}.%(ext)s',\n",
    "        'postprocessors': [{\n",
    "            'key': 'FFmpegVideoConvertor',\n",
    "            'preferedformat': 'mp4',\n",
    "        }],\n",
    "    }\n",
    "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "        info = ydl.extract_info(url, download=True)\n",
    "        filename = ydl.prepare_filename(info)\n",
    "    \n",
    "    # The file extension might have changed, so we need to get the actual filename\n",
    "    actual_filename = glob.glob(f\"{video_id}.*\")[0]\n",
    "    return actual_filename\n",
    "\n",
    "def process_with_deepgram(file_path):\n",
    "    load_dotenv()\n",
    "    \n",
    "    url = \"https://api.deepgram.com/v1/listen\"\n",
    "    params = {\n",
    "        \"diarize\": \"true\",\n",
    "        \"punctuate\": \"true\",\n",
    "        \"utterances\": \"true\"\n",
    "    }\n",
    "    \n",
    "    DEEPGRAM_API_KEY = os.getenv(\"DEEPGRAM_API_KEY\")\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Token {DEEPGRAM_API_KEY}\",\n",
    "        \"Content-Type\": \"video/webm\"\n",
    "    }\n",
    "    \n",
    "    with open(file_path, \"rb\") as file:\n",
    "        data = file.read()\n",
    "    \n",
    "    # Create a retry strategy\n",
    "    retry_strategy = Retry(\n",
    "        total=3,\n",
    "        backoff_factor=1,\n",
    "        status_forcelist=[429, 500, 502, 503, 504],\n",
    "        allowed_methods=[\"HEAD\", \"GET\", \"OPTIONS\", \"POST\"]\n",
    "    )\n",
    "    adapter = HTTPAdapter(max_retries=retry_strategy)\n",
    "    \n",
    "    # Create a session with the retry strategy\n",
    "    session = requests.Session()\n",
    "    session.mount(\"https://\", adapter)\n",
    "    \n",
    "    try:\n",
    "        response = session.post(url, params=params, headers=headers, data=data, verify=True, timeout=30)\n",
    "        response.raise_for_status()  # Raises an HTTPError if the HTTP request returned an unsuccessful status code\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            result = response.json()\n",
    "            \n",
    "            # Create 'transcripts' directory if it doesn't exist\n",
    "            os.makedirs('transcripts', exist_ok=True)\n",
    "            \n",
    "            # Generate output filename in the 'transcripts' directory\n",
    "            output_filename = os.path.join('transcripts', f\"{os.path.splitext(os.path.basename(file_path))[0]}_transcript.json\")\n",
    "            \n",
    "            with open(output_filename, \"w\") as outfile:\n",
    "                json.dump(result, outfile, indent=2)\n",
    "            print(f\"Transcript saved to {output_filename}\")\n",
    "            return output_filename\n",
    "        else:\n",
    "            print(f\"Error: {response.status_code}\")\n",
    "            print(response.text)\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"An error occurred during the request: {e}\")\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"Error decoding JSON response\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "    return None\n",
    "\n",
    "\n",
    "\n",
    "# Create widgets\n",
    "url_input = widgets.Text(description=\"YouTube URL:\", layout=widgets.Layout(width='500px'))\n",
    "submit_button = widgets.Button(description=\"Submit\")\n",
    "output = widgets.Output()\n",
    "transcript_output = widgets.Output()\n",
    "\n",
    "# Global variable to store the transcript path\n",
    "global_transcript_path = None\n",
    "\n",
    "# Define button click event\n",
    "def on_button_click(b):\n",
    "    global global_transcript_path\n",
    "    with output:\n",
    "        output.clear_output()\n",
    "        print(\"Downloading video...\")\n",
    "        try:\n",
    "            video_path = download_video(url_input.value)\n",
    "            print(f\"Download complete! Video saved at: {video_path}\")\n",
    "            os.makedirs('videos_webm', exist_ok=True)\n",
    "            display(HTML(f'<video width=\"320\" height=\"240\" controls><source src=\"{video_path}\" type=\"video/webm\"></video>'))\n",
    "            \n",
    "            # Create download link\n",
    "            download_link = f'<a href=\"{video_path}\" download>Download Video</a>'\n",
    "            display(HTML(download_link))\n",
    "            \n",
    "            print(\"Processing with Deepgram...\")\n",
    "            transcript_path = process_with_deepgram(video_path)\n",
    "            if transcript_path:\n",
    "                print(f\"Transcript generated and saved at: {transcript_path}\")\n",
    "                # Create download link for transcript\n",
    "                transcript_download_link = f'<a href=\"{transcript_path}\" download>Download Transcript</a>'\n",
    "                display(HTML(transcript_download_link))\n",
    "                global_transcript_path = transcript_path\n",
    "            else:\n",
    "                print(\"Failed to generate transcript.\")\n",
    "                global_transcript_path = None\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {str(e)}\")\n",
    "            global_transcript_path = None\n",
    "    \n",
    "    # Update the transcript output\n",
    "    with transcript_output:\n",
    "        transcript_output.clear_output()\n",
    "        if global_transcript_path:\n",
    "            print(f\"Transcript path: {global_transcript_path}\")\n",
    "        else:\n",
    "            print(\"No transcript generated.\")\n",
    "\n",
    "# Connect the button click event to the function\n",
    "submit_button.on_click(on_button_click)\n",
    "\n",
    "# Display widgets\n",
    "display(url_input, submit_button, output, transcript_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e49918-09bd-4dea-aa8c-effeda9ea13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.youtube.com/watch?v=yJzjyYL8l5Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d735212f-9130-4b4b-96e6-1a68da3efcb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'transcripts/yJzjyYL8l5Y_transcript.json'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_transcript_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "905e0110-9cf7-49c6-b306-45db637c6a34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['book', 'drink', 'computer', ..., 'weigh', 'wheelchair', 'whistle'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# Load JSON data from file\n",
    "with open('WLASL_v0.3.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Extract and format gloss values\n",
    "def get_gloss_array(data):\n",
    "    gloss_values = []\n",
    "\n",
    "    for item in data:\n",
    "        if 'gloss' in item:\n",
    "            gloss_values.append(item['gloss'])\n",
    "\n",
    "    # Convert to numpy array\n",
    "    gloss_array = np.array(gloss_values, dtype=object)\n",
    "    return gloss_array\n",
    "\n",
    "# Get the gloss array\n",
    "unique_words = get_gloss_array(data)\n",
    "\n",
    "unique_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "73bdc5a0-f0dd-47d7-801a-9ea183e3f9e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'word': 'welcome',\n",
       "  'start': 3.32,\n",
       "  'end': 3.82,\n",
       "  'confidence': 0.99609375,\n",
       "  'speaker': 0,\n",
       "  'speaker_confidence': 1.0,\n",
       "  'punctuated_word': 'Welcome'},\n",
       " {'word': 'to',\n",
       "  'start': 3.8799999,\n",
       "  'end': 4.04,\n",
       "  'confidence': 0.99560547,\n",
       "  'speaker': 0,\n",
       "  'speaker_confidence': 1.0,\n",
       "  'punctuated_word': 'to'},\n",
       " {'word': 'our',\n",
       "  'start': 4.04,\n",
       "  'end': 4.2799997,\n",
       "  'confidence': 0.9975586,\n",
       "  'speaker': 0,\n",
       "  'speaker_confidence': 1.0,\n",
       "  'punctuated_word': 'our'},\n",
       " {'word': 'basic',\n",
       "  'start': 4.2799997,\n",
       "  'end': 4.7799997,\n",
       "  'confidence': 0.8647461,\n",
       "  'speaker': 0,\n",
       "  'speaker_confidence': 1.0,\n",
       "  'punctuated_word': 'basic'},\n",
       " {'word': 'series',\n",
       "  'start': 4.8399997,\n",
       "  'end': 5.24,\n",
       "  'confidence': 0.99609375,\n",
       "  'speaker': 0,\n",
       "  'speaker_confidence': 1.0,\n",
       "  'punctuated_word': 'series.'},\n",
       " {'word': 'these',\n",
       "  'start': 5.8799996,\n",
       "  'end': 6.2,\n",
       "  'confidence': 0.9946289,\n",
       "  'speaker': 0,\n",
       "  'speaker_confidence': 1.0,\n",
       "  'punctuated_word': 'These'},\n",
       " {'word': 'videos',\n",
       "  'start': 6.2,\n",
       "  'end': 6.68,\n",
       "  'confidence': 0.9921875,\n",
       "  'speaker': 0,\n",
       "  'speaker_confidence': 1.0,\n",
       "  'punctuated_word': 'videos'},\n",
       " {'word': 'have',\n",
       "  'start': 6.68,\n",
       "  'end': 6.92,\n",
       "  'confidence': 0.9941406,\n",
       "  'speaker': 0,\n",
       "  'speaker_confidence': 1.0,\n",
       "  'punctuated_word': 'have'},\n",
       " {'word': 'real',\n",
       "  'start': 6.92,\n",
       "  'end': 7.24,\n",
       "  'confidence': 0.9970703,\n",
       "  'speaker': 0,\n",
       "  'speaker_confidence': 1.0,\n",
       "  'punctuated_word': 'real'},\n",
       " {'word': 'english',\n",
       "  'start': 7.48,\n",
       "  'end': 7.98,\n",
       "  'confidence': 0.99902344,\n",
       "  'speaker': 0,\n",
       "  'speaker_confidence': 1.0,\n",
       "  'punctuated_word': 'English'},\n",
       " {'word': 'for',\n",
       "  'start': 8.2,\n",
       "  'end': 8.44,\n",
       "  'confidence': 0.99609375,\n",
       "  'speaker': 0,\n",
       "  'speaker_confidence': 1.0,\n",
       "  'punctuated_word': 'for'},\n",
       " {'word': 'low',\n",
       "  'start': 8.44,\n",
       "  'end': 8.76,\n",
       "  'confidence': 0.99609375,\n",
       "  'speaker': 0,\n",
       "  'speaker_confidence': 1.0,\n",
       "  'punctuated_word': 'low'},\n",
       " {'word': 'level',\n",
       "  'start': 8.76,\n",
       "  'end': 9.26,\n",
       "  'confidence': 0.99365234,\n",
       "  'speaker': 0,\n",
       "  'speaker_confidence': 1.0,\n",
       "  'punctuated_word': 'level'},\n",
       " {'word': 'beginners',\n",
       "  'start': 9.32,\n",
       "  'end': 9.559999,\n",
       "  'confidence': 0.91845703,\n",
       "  'speaker': 0,\n",
       "  'speaker_confidence': 1.0,\n",
       "  'punctuated_word': 'beginners.'},\n",
       " {'word': 'our',\n",
       "  'start': 10.450819,\n",
       "  'end': 10.84836,\n",
       "  'confidence': 0.9975586,\n",
       "  'speaker': 0,\n",
       "  'speaker_confidence': 1.0,\n",
       "  'punctuated_word': 'Our'},\n",
       " {'word': 'teachers',\n",
       "  'start': 10.84836,\n",
       "  'end': 11.166393,\n",
       "  'confidence': 0.85253906,\n",
       "  'speaker': 0,\n",
       "  'speaker_confidence': 1.0,\n",
       "  'punctuated_word': 'teachers'},\n",
       " {'word': 'teach',\n",
       "  'start': 11.166393,\n",
       "  'end': 11.404918,\n",
       "  'confidence': 0.6430664,\n",
       "  'speaker': 0,\n",
       "  'speaker_confidence': 1.0,\n",
       "  'punctuated_word': 'teach'},\n",
       " {'word': 'you',\n",
       "  'start': 11.404918,\n",
       "  'end': 11.643442,\n",
       "  'confidence': 0.9550781,\n",
       "  'speaker': 0,\n",
       "  'speaker_confidence': 1.0,\n",
       "  'punctuated_word': 'you'},\n",
       " {'word': 'words',\n",
       "  'start': 11.643442,\n",
       "  'end': 12.120491,\n",
       "  'confidence': 0.9995117,\n",
       "  'speaker': 0,\n",
       "  'speaker_confidence': 1.0,\n",
       "  'punctuated_word': 'words'},\n",
       " {'word': 'and',\n",
       "  'start': 12.120491,\n",
       "  'end': 12.59754,\n",
       "  'confidence': 0.9970703,\n",
       "  'speaker': 0,\n",
       "  'speaker_confidence': 1.0,\n",
       "  'punctuated_word': 'and'},\n",
       " {'word': 'expressions',\n",
       "  'start': 12.59754,\n",
       "  'end': 13.07459,\n",
       "  'confidence': 1.0,\n",
       "  'speaker': 0,\n",
       "  'speaker_confidence': 1.0,\n",
       "  'punctuated_word': 'expressions,'},\n",
       " {'word': 'you',\n",
       "  'start': 13.631147,\n",
       "  'end': 13.790163,\n",
       "  'confidence': 0.9995117,\n",
       "  'speaker': 0,\n",
       "  'speaker_confidence': 1.0,\n",
       "  'punctuated_word': 'you'},\n",
       " {'word': 'should',\n",
       "  'start': 13.790163,\n",
       "  'end': 14.028688,\n",
       "  'confidence': 0.9921875,\n",
       "  'speaker': 0,\n",
       "  'speaker_confidence': 1.0,\n",
       "  'punctuated_word': 'should'},\n",
       " {'word': 'know',\n",
       "  'start': 14.028688,\n",
       "  'end': 14.267212,\n",
       "  'confidence': 0.98779297,\n",
       "  'speaker': 0,\n",
       "  'speaker_confidence': 1.0,\n",
       "  'punctuated_word': 'know.'},\n",
       " {'word': 'all',\n",
       "  'start': 15.062294,\n",
       "  'end': 15.141803,\n",
       "  'confidence': 0.9995117,\n",
       "  'speaker': 0,\n",
       "  'speaker_confidence': 1.0,\n",
       "  'punctuated_word': 'All'},\n",
       " {'word': 'of',\n",
       "  'start': 15.141803,\n",
       "  'end': 15.380327,\n",
       "  'confidence': 0.9946289,\n",
       "  'speaker': 0,\n",
       "  'speaker_confidence': 1.0,\n",
       "  'punctuated_word': 'of'},\n",
       " {'word': 'these',\n",
       "  'start': 15.380327,\n",
       "  'end': 15.69836,\n",
       "  'confidence': 0.99853516,\n",
       "  'speaker': 0,\n",
       "  'speaker_confidence': 1.0,\n",
       "  'punctuated_word': 'these'},\n",
       " {'word': 'videos',\n",
       "  'start': 15.69836,\n",
       "  'end': 16.17541,\n",
       "  'confidence': 0.99560547,\n",
       "  'speaker': 0,\n",
       "  'speaker_confidence': 1.0,\n",
       "  'punctuated_word': 'videos'},\n",
       " {'word': 'are',\n",
       "  'start': 16.17541,\n",
       "  'end': 16.413933,\n",
       "  'confidence': 0.99853516,\n",
       "  'speaker': 0,\n",
       "  'speaker_confidence': 1.0,\n",
       "  'punctuated_word': 'are'},\n",
       " {'word': 'helpful',\n",
       "  'start': 16.413933,\n",
       "  'end': 16.890984,\n",
       "  'confidence': 0.99316406,\n",
       "  'speaker': 0,\n",
       "  'speaker_confidence': 1.0,\n",
       "  'punctuated_word': 'helpful'},\n",
       " {'word': 'to',\n",
       "  'start': 16.890984,\n",
       "  'end': 17.209015,\n",
       "  'confidence': 0.99902344,\n",
       "  'speaker': 0,\n",
       "  'speaker_confidence': 1.0,\n",
       "  'punctuated_word': 'to'},\n",
       " {'word': 'improve',\n",
       "  'start': 17.209015,\n",
       "  'end': 17.44754,\n",
       "  'confidence': 0.9995117,\n",
       "  'speaker': 0,\n",
       "  'speaker_confidence': 1.0,\n",
       "  'punctuated_word': 'improve'},\n",
       " {'word': 'your',\n",
       "  'start': 17.44754,\n",
       "  'end': 17.686066,\n",
       "  'confidence': 0.9975586,\n",
       "  'speaker': 0,\n",
       "  'speaker_confidence': 1.0,\n",
       "  'punctuated_word': 'your'},\n",
       " {'word': 'english',\n",
       "  'start': 17.845081,\n",
       "  'end': 18.004097,\n",
       "  'confidence': 1.0,\n",
       "  'speaker': 0,\n",
       "  'speaker_confidence': 1.0,\n",
       "  'punctuated_word': 'English,'},\n",
       " {'word': 'so',\n",
       "  'start': 18.481148,\n",
       "  'end': 18.719671,\n",
       "  'confidence': 0.98876953,\n",
       "  'speaker': 0,\n",
       "  'speaker_confidence': 1.0,\n",
       "  'punctuated_word': 'so'},\n",
       " {'word': 'never',\n",
       "  'start': 18.719671,\n",
       "  'end': 18.958195,\n",
       "  'confidence': 0.99902344,\n",
       "  'speaker': 0,\n",
       "  'speaker_confidence': 1.0,\n",
       "  'punctuated_word': 'never'},\n",
       " {'word': 'give',\n",
       "  'start': 18.958195,\n",
       "  'end': 19.117212,\n",
       "  'confidence': 0.99853516,\n",
       "  'speaker': 0,\n",
       "  'speaker_confidence': 1.0,\n",
       "  'punctuated_word': 'give'},\n",
       " {'word': 'up',\n",
       "  'start': 19.117212,\n",
       "  'end': 19.27623,\n",
       "  'confidence': 0.8227539,\n",
       "  'speaker': 0,\n",
       "  'speaker_confidence': 1.0,\n",
       "  'punctuated_word': 'up.'},\n",
       " {'word': \"it's\",\n",
       "  'start': 19.9285,\n",
       "  'end': 20.327137,\n",
       "  'confidence': 0.9975586,\n",
       "  'speaker': 0,\n",
       "  'speaker_confidence': 1.0,\n",
       "  'punctuated_word': \"It's\"},\n",
       " {'word': 'important',\n",
       "  'start': 20.327137,\n",
       "  'end': 20.566319,\n",
       "  'confidence': 0.9995117,\n",
       "  'speaker': 0,\n",
       "  'speaker_confidence': 1.0,\n",
       "  'punctuated_word': 'important'},\n",
       " {'word': 'to',\n",
       "  'start': 20.566319,\n",
       "  'end': 20.8055,\n",
       "  'confidence': 1.0,\n",
       "  'speaker': 0,\n",
       "  'speaker_confidence': 1.0,\n",
       "  'punctuated_word': 'to'},\n",
       " {'word': 'watch',\n",
       "  'start': 20.8055,\n",
       "  'end': 21.044682,\n",
       "  'confidence': 0.99902344,\n",
       "  'speaker': 0,\n",
       "  'speaker_confidence': 1.0,\n",
       "  'punctuated_word': 'watch'},\n",
       " {'word': 'these',\n",
       "  'start': 21.044682,\n",
       "  'end': 21.36359,\n",
       "  'confidence': 0.99658203,\n",
       "  'speaker': 0,\n",
       "  'speaker_confidence': 1.0,\n",
       "  'punctuated_word': 'these'},\n",
       " {'word': 'videos',\n",
       "  'start': 21.36359,\n",
       "  'end': 21.86359,\n",
       "  'confidence': 0.9975586,\n",
       "  'speaker': 0,\n",
       "  'speaker_confidence': 1.0,\n",
       "  'punctuated_word': 'videos'},\n",
       " {'word': 'and',\n",
       "  'start': 22.160864,\n",
       "  'end': 22.400045,\n",
       "  'confidence': 0.99902344,\n",
       "  'speaker': 0,\n",
       "  'speaker_confidence': 1.0,\n",
       "  'punctuated_word': 'and'},\n",
       " {'word': 'also',\n",
       "  'start': 22.400045,\n",
       "  'end': 22.798681,\n",
       "  'confidence': 0.99902344,\n",
       "  'speaker': 0,\n",
       "  'speaker_confidence': 1.0,\n",
       "  'punctuated_word': 'also'},\n",
       " {'word': 'do',\n",
       "  'start': 22.798681,\n",
       "  'end': 23.037863,\n",
       "  'confidence': 0.99853516,\n",
       "  'speaker': 0,\n",
       "  'speaker_confidence': 1.0,\n",
       "  'punctuated_word': 'do'},\n",
       " {'word': 'some',\n",
       "  'start': 23.037863,\n",
       "  'end': 23.356773,\n",
       "  'confidence': 0.99902344,\n",
       "  'speaker': 0,\n",
       "  'speaker_confidence': 1.0,\n",
       "  'punctuated_word': 'some'},\n",
       " {'word': 'self',\n",
       "  'start': 23.356773,\n",
       "  'end': 23.75541,\n",
       "  'confidence': 0.99902344,\n",
       "  'speaker': 0,\n",
       "  'speaker_confidence': 1.0,\n",
       "  'punctuated_word': 'self'},\n",
       " {'word': 'study',\n",
       "  'start': 23.75541,\n",
       "  'end': 24.074318,\n",
       "  'confidence': 0.95654297,\n",
       "  'speaker': 0,\n",
       "  'speaker_confidence': 1.0,\n",
       "  'punctuated_word': 'study.'},\n",
       " {'word': 'check',\n",
       "  'start': 24.712135,\n",
       "  'end': 25.031044,\n",
       "  'confidence': 0.9995117,\n",
       "  'speaker': 0,\n",
       "  'speaker_confidence': 1.0,\n",
       "  'punctuated_word': 'Check'},\n",
       " {'word': 'any',\n",
       "  'start': 25.031044,\n",
       "  'end': 25.270227,\n",
       "  'confidence': 0.9995117,\n",
       "  'speaker': 0,\n",
       "  'speaker_confidence': 1.0,\n",
       "  'punctuated_word': 'any'},\n",
       " {'word': 'new',\n",
       "  'start': 25.270227,\n",
       "  'end': 25.509409,\n",
       "  'confidence': 0.9863281,\n",
       "  'speaker': 0,\n",
       "  'speaker_confidence': 1.0,\n",
       "  'punctuated_word': 'new'},\n",
       " {'word': 'words',\n",
       "  'start': 25.509409,\n",
       "  'end': 25.828318,\n",
       "  'confidence': 0.99902344,\n",
       "  'speaker': 0,\n",
       "  'speaker_confidence': 1.0,\n",
       "  'punctuated_word': 'words'},\n",
       " {'word': 'you',\n",
       "  'start': 25.828318,\n",
       "  'end': 25.987772,\n",
       "  'confidence': 0.9995117,\n",
       "  'speaker': 0,\n",
       "  'speaker_confidence': 1.0,\n",
       "  'punctuated_word': 'you'},\n",
       " {'word': \"don't\",\n",
       "  'start': 25.987772,\n",
       "  'end': 26.487772,\n",
       "  'confidence': 0.9995117,\n",
       "  'speaker': 0,\n",
       "  'speaker_confidence': 1.0,\n",
       "  'punctuated_word': \"don't\"},\n",
       " {'word': 'understand',\n",
       "  'start': 26.545864,\n",
       "  'end': 27.024227,\n",
       "  'confidence': 1.0,\n",
       "  'speaker': 0,\n",
       "  'speaker_confidence': 1.0,\n",
       "  'punctuated_word': 'understand'},\n",
       " {'word': 'in',\n",
       "  'start': 27.024227,\n",
       "  'end': 27.183681,\n",
       "  'confidence': 0.93066406,\n",
       "  'speaker': 0,\n",
       "  'speaker_confidence': 1.0,\n",
       "  'punctuated_word': 'in'},\n",
       " {'word': 'a',\n",
       "  'start': 27.183681,\n",
       "  'end': 27.50259,\n",
       "  'confidence': 0.9345703,\n",
       "  'speaker': 0,\n",
       "  'speaker_confidence': 1.0,\n",
       "  'punctuated_word': 'a'},\n",
       " {'word': 'dictionary',\n",
       "  'start': 27.50259,\n",
       "  'end': 27.821499,\n",
       "  'confidence': 0.9980469,\n",
       "  'speaker': 0,\n",
       "  'speaker_confidence': 1.0,\n",
       "  'punctuated_word': 'dictionary,'},\n",
       " {'word': 'and',\n",
       "  'start': 28.393917,\n",
       "  'end': 28.631752,\n",
       "  'confidence': 0.99853516,\n",
       "  'speaker': 0,\n",
       "  'speaker_confidence': 1.0,\n",
       "  'punctuated_word': 'and'},\n",
       " {'word': 'try',\n",
       "  'start': 28.631752,\n",
       "  'end': 28.869587,\n",
       "  'confidence': 0.99072266,\n",
       "  'speaker': 0,\n",
       "  'speaker_confidence': 1.0,\n",
       "  'punctuated_word': 'try'},\n",
       " {'word': 'to',\n",
       "  'start': 28.869587,\n",
       "  'end': 29.1867,\n",
       "  'confidence': 0.9995117,\n",
       "  'speaker': 0,\n",
       "  'speaker_confidence': 1.0,\n",
       "  'punctuated_word': 'to'},\n",
       " {'word': 'always',\n",
       "  'start': 29.1867,\n",
       "  'end': 29.6867,\n",
       "  'confidence': 1.0,\n",
       "  'speaker': 0,\n",
       "  'speaker_confidence': 1.0,\n",
       "  'punctuated_word': 'always'},\n",
       " {'word': 'repeat',\n",
       "  'start': 29.900206,\n",
       "  'end': 30.400206,\n",
       "  'confidence': 0.9995117,\n",
       "  'speaker': 0,\n",
       "  'speaker_confidence': 1.0,\n",
       "  'punctuated_word': 'repeat'},\n",
       " {'word': 'what',\n",
       "  'start': 30.534433,\n",
       "  'end': 30.772268,\n",
       "  'confidence': 1.0,\n",
       "  'speaker': 0,\n",
       "  'speaker_confidence': 1.0,\n",
       "  'punctuated_word': 'what'},\n",
       " {'word': 'the',\n",
       "  'start': 30.772268,\n",
       "  'end': 31.08938,\n",
       "  'confidence': 0.9980469,\n",
       "  'speaker': 0,\n",
       "  'speaker_confidence': 1.0,\n",
       "  'punctuated_word': 'the'},\n",
       " {'word': 'teacher',\n",
       "  'start': 31.08938,\n",
       "  'end': 31.327217,\n",
       "  'confidence': 0.98876953,\n",
       "  'speaker': 0,\n",
       "  'speaker_confidence': 1.0,\n",
       "  'punctuated_word': 'teacher'},\n",
       " {'word': 'says',\n",
       "  'start': 31.327217,\n",
       "  'end': 31.64433,\n",
       "  'confidence': 0.99609375,\n",
       "  'speaker': 0,\n",
       "  'speaker_confidence': 1.0,\n",
       "  'punctuated_word': 'says.'},\n",
       " {'word': 'these',\n",
       "  'start': 32.51639,\n",
       "  'end': 32.754227,\n",
       "  'confidence': 0.99853516,\n",
       "  'speaker': 0,\n",
       "  'speaker_confidence': 1.0,\n",
       "  'punctuated_word': 'These'},\n",
       " {'word': 'videos',\n",
       "  'start': 32.754227,\n",
       "  'end': 33.229897,\n",
       "  'confidence': 0.9980469,\n",
       "  'speaker': 0,\n",
       "  'speaker_confidence': 1.0,\n",
       "  'punctuated_word': 'videos'},\n",
       " {'word': 'can',\n",
       "  'start': 33.229897,\n",
       "  'end': 33.46773,\n",
       "  'confidence': 0.9980469,\n",
       "  'speaker': 0,\n",
       "  'speaker_confidence': 1.0,\n",
       "  'punctuated_word': 'can'},\n",
       " {'word': 'be',\n",
       "  'start': 33.46773,\n",
       "  'end': 33.62629,\n",
       "  'confidence': 0.9995117,\n",
       "  'speaker': 0,\n",
       "  'speaker_confidence': 1.0,\n",
       "  'punctuated_word': 'be'},\n",
       " {'word': 'difficult',\n",
       "  'start': 33.62629,\n",
       "  'end': 34.12629,\n",
       "  'confidence': 1.0,\n",
       "  'speaker': 0,\n",
       "  'speaker_confidence': 1.0,\n",
       "  'punctuated_word': 'difficult'},\n",
       " {'word': 'to',\n",
       "  'start': 34.181236,\n",
       "  'end': 34.656906,\n",
       "  'confidence': 0.99902344,\n",
       "  'speaker': 0,\n",
       "  'speaker_confidence': 1.0,\n",
       "  'punctuated_word': 'to'},\n",
       " {'word': 'understand',\n",
       "  'start': 34.656906,\n",
       "  'end': 35.0533,\n",
       "  'confidence': 0.9995117,\n",
       "  'speaker': 0,\n",
       "  'speaker_confidence': 1.0,\n",
       "  'punctuated_word': 'understand'},\n",
       " {'word': 'at',\n",
       "  'start': 35.0533,\n",
       "  'end': 35.291134,\n",
       "  'confidence': 0.9975586,\n",
       "  'speaker': 0,\n",
       "  'speaker_confidence': 1.0,\n",
       "  'punctuated_word': 'at'},\n",
       " {'word': 'first',\n",
       "  'start': 35.291134,\n",
       "  'end': 35.608246,\n",
       "  'confidence': 0.99853516,\n",
       "  'speaker': 0,\n",
       "  'speaker_confidence': 1.0,\n",
       "  'punctuated_word': 'first,'},\n",
       " {'word': 'but',\n",
       "  'start': 36.33771,\n",
       "  'end': 36.576187,\n",
       "  'confidence': 0.9975586,\n",
       "  'speaker': 0,\n",
       "  'speaker_confidence': 1.0,\n",
       "  'punctuated_word': 'but'},\n",
       " {'word': 'keep',\n",
       "  'start': 36.576187,\n",
       "  'end': 36.81466,\n",
       "  'confidence': 0.9970703,\n",
       "  'speaker': 0,\n",
       "  'speaker_confidence': 1.0,\n",
       "  'punctuated_word': 'keep'},\n",
       " {'word': 'watching',\n",
       "  'start': 36.81466,\n",
       "  'end': 37.21212,\n",
       "  'confidence': 0.9970703,\n",
       "  'speaker': 0,\n",
       "  'speaker_confidence': 1.0,\n",
       "  'punctuated_word': 'watching.'},\n",
       " {'word': 'you',\n",
       "  'start': 37.76856,\n",
       "  'end': 38.007034,\n",
       "  'confidence': 0.9902344,\n",
       "  'speaker': 0,\n",
       "  'speaker_confidence': 1.0,\n",
       "  'punctuated_word': 'You'},\n",
       " {'word': 'will',\n",
       "  'start': 38.007034,\n",
       "  'end': 38.245506,\n",
       "  'confidence': 0.96777344,\n",
       "  'speaker': 0,\n",
       "  'speaker_confidence': 1.0,\n",
       "  'punctuated_word': 'will'},\n",
       " {'word': 'get',\n",
       "  'start': 38.245506,\n",
       "  'end': 38.483982,\n",
       "  'confidence': 0.99560547,\n",
       "  'speaker': 0,\n",
       "  'speaker_confidence': 1.0,\n",
       "  'punctuated_word': 'get'},\n",
       " {'word': 'better',\n",
       "  'start': 38.483982,\n",
       "  'end': 38.80195,\n",
       "  'confidence': 0.99658203,\n",
       "  'speaker': 0,\n",
       "  'speaker_confidence': 1.0,\n",
       "  'punctuated_word': 'better,'},\n",
       " {'word': 'you',\n",
       "  'start': 39.35839,\n",
       "  'end': 39.596863,\n",
       "  'confidence': 0.98828125,\n",
       "  'speaker': 0,\n",
       "  'speaker_confidence': 1.0,\n",
       "  'punctuated_word': 'you'},\n",
       " {'word': 'will',\n",
       "  'start': 39.596863,\n",
       "  'end': 39.994324,\n",
       "  'confidence': 0.9604492,\n",
       "  'speaker': 0,\n",
       "  'speaker_confidence': 1.0,\n",
       "  'punctuated_word': 'will'},\n",
       " {'word': 'improve',\n",
       "  'start': 39.994324,\n",
       "  'end': 40.312286,\n",
       "  'confidence': 0.99853516,\n",
       "  'speaker': 0,\n",
       "  'speaker_confidence': 1.0,\n",
       "  'punctuated_word': 'improve.'},\n",
       " {'word': \"let's\",\n",
       "  'start': 41.107204,\n",
       "  'end': 41.345676,\n",
       "  'confidence': 0.9970703,\n",
       "  'speaker': 0,\n",
       "  'speaker_confidence': 1.0,\n",
       "  'punctuated_word': \"Let's\"},\n",
       " {'word': 'get',\n",
       "  'start': 41.345676,\n",
       "  'end': 41.584152,\n",
       "  'confidence': 0.99902344,\n",
       "  'speaker': 0,\n",
       "  'speaker_confidence': 1.0,\n",
       "  'punctuated_word': 'get'},\n",
       " {'word': 'started',\n",
       "  'start': 41.584152,\n",
       "  'end': 41.98161,\n",
       "  'confidence': 0.99902344,\n",
       "  'speaker': 0,\n",
       "  'speaker_confidence': 1.0,\n",
       "  'punctuated_word': 'started.'}]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json \n",
    "\n",
    "\n",
    "global_transcript_path = 'transcripts/S0P3hjM0DDM_transcript.json'\n",
    "with open(global_transcript_path, 'r') as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "words = data['results']['channels'][0]['alternatives'][0]['words']\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "245a8715-be8f-40aa-9036-dbe11c93f499",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: welcome, Start: 3.32, End: 3.82, Tag: Yes\n",
      "Word: to, Start: 3.8799999, End: 4.04, Tag: Yes\n",
      "Word: our, Start: 4.04, End: 4.2799997, Tag: Yes\n",
      "Word: basic, Start: 4.2799997, End: 4.7799997, Tag: Yes\n",
      "Word: series, Start: 4.8399997, End: 5.24, Tag: No\n",
      "Word: these, Start: 5.8799996, End: 6.2, Tag: No\n",
      "Word: videos, Start: 6.2, End: 6.68, Tag: No\n",
      "Word: have, Start: 6.68, End: 6.92, Tag: Yes\n",
      "Word: real, Start: 6.92, End: 7.24, Tag: Yes\n",
      "Word: english, Start: 7.48, End: 7.98, Tag: Yes\n",
      "Word: for, Start: 8.2, End: 8.44, Tag: Yes\n",
      "Word: low, Start: 8.44, End: 8.76, Tag: No\n",
      "Word: level, Start: 8.76, End: 9.26, Tag: No\n",
      "Word: beginners, Start: 9.32, End: 9.559999, Tag: No\n",
      "Word: our, Start: 10.450819, End: 10.84836, Tag: Yes\n",
      "Word: teachers, Start: 10.84836, End: 11.166393, Tag: No\n",
      "Word: teach, Start: 11.166393, End: 11.404918, Tag: Yes\n",
      "Word: you, Start: 11.404918, End: 11.643442, Tag: Yes\n",
      "Word: words, Start: 11.643442, End: 12.120491, Tag: No\n",
      "Word: and, Start: 12.120491, End: 12.59754, Tag: Yes\n",
      "Word: expressions, Start: 12.59754, End: 13.07459, Tag: No\n",
      "Word: you, Start: 13.631147, End: 13.790163, Tag: Yes\n",
      "Word: should, Start: 13.790163, End: 14.028688, Tag: Yes\n",
      "Word: know, Start: 14.028688, End: 14.267212, Tag: Yes\n",
      "Word: all, Start: 15.062294, End: 15.141803, Tag: Yes\n",
      "Word: of, Start: 15.141803, End: 15.380327, Tag: No\n",
      "Word: these, Start: 15.380327, End: 15.69836, Tag: No\n",
      "Word: videos, Start: 15.69836, End: 16.17541, Tag: No\n",
      "Word: are, Start: 16.17541, End: 16.413933, Tag: No\n",
      "Word: helpful, Start: 16.413933, End: 16.890984, Tag: No\n",
      "Word: to, Start: 16.890984, End: 17.209015, Tag: Yes\n",
      "Word: improve, Start: 17.209015, End: 17.44754, Tag: Yes\n",
      "Word: your, Start: 17.44754, End: 17.686066, Tag: Yes\n",
      "Word: english, Start: 17.845081, End: 18.004097, Tag: Yes\n",
      "Word: so, Start: 18.481148, End: 18.719671, Tag: No\n",
      "Word: never, Start: 18.719671, End: 18.958195, Tag: Yes\n",
      "Word: give, Start: 18.958195, End: 19.117212, Tag: Yes\n",
      "Word: up, Start: 19.117212, End: 19.27623, Tag: Yes\n",
      "Word: it's, Start: 19.9285, End: 20.327137, Tag: No\n",
      "Word: important, Start: 20.327137, End: 20.566319, Tag: Yes\n",
      "Word: to, Start: 20.566319, End: 20.8055, Tag: Yes\n",
      "Word: watch, Start: 20.8055, End: 21.044682, Tag: Yes\n",
      "Word: these, Start: 21.044682, End: 21.36359, Tag: No\n",
      "Word: videos, Start: 21.36359, End: 21.86359, Tag: No\n",
      "Word: and, Start: 22.160864, End: 22.400045, Tag: Yes\n",
      "Word: also, Start: 22.400045, End: 22.798681, Tag: Yes\n",
      "Word: do, Start: 22.798681, End: 23.037863, Tag: No\n",
      "Word: some, Start: 23.037863, End: 23.356773, Tag: Yes\n",
      "Word: self, Start: 23.356773, End: 23.75541, Tag: No\n",
      "Word: study, Start: 23.75541, End: 24.074318, Tag: Yes\n",
      "Word: check, Start: 24.712135, End: 25.031044, Tag: Yes\n",
      "Word: any, Start: 25.031044, End: 25.270227, Tag: Yes\n",
      "Word: new, Start: 25.270227, End: 25.509409, Tag: Yes\n",
      "Word: words, Start: 25.509409, End: 25.828318, Tag: No\n",
      "Word: you, Start: 25.828318, End: 25.987772, Tag: Yes\n",
      "Word: don't, Start: 25.987772, End: 26.487772, Tag: No\n",
      "Word: understand, Start: 26.545864, End: 27.024227, Tag: Yes\n",
      "Word: in, Start: 27.024227, End: 27.183681, Tag: Yes\n",
      "Word: a, Start: 27.183681, End: 27.50259, Tag: Yes\n",
      "Word: dictionary, Start: 27.50259, End: 27.821499, Tag: Yes\n",
      "Word: and, Start: 28.393917, End: 28.631752, Tag: Yes\n",
      "Word: try, Start: 28.631752, End: 28.869587, Tag: Yes\n",
      "Word: to, Start: 28.869587, End: 29.1867, Tag: Yes\n",
      "Word: always, Start: 29.1867, End: 29.6867, Tag: Yes\n",
      "Word: repeat, Start: 29.900206, End: 30.400206, Tag: Yes\n",
      "Word: what, Start: 30.534433, End: 30.772268, Tag: Yes\n",
      "Word: the, Start: 30.772268, End: 31.08938, Tag: No\n",
      "Word: teacher, Start: 31.08938, End: 31.327217, Tag: Yes\n",
      "Word: says, Start: 31.327217, End: 31.64433, Tag: No\n",
      "Word: these, Start: 32.51639, End: 32.754227, Tag: No\n",
      "Word: videos, Start: 32.754227, End: 33.229897, Tag: No\n",
      "Word: can, Start: 33.229897, End: 33.46773, Tag: Yes\n",
      "Word: be, Start: 33.46773, End: 33.62629, Tag: No\n",
      "Word: difficult, Start: 33.62629, End: 34.12629, Tag: Yes\n",
      "Word: to, Start: 34.181236, End: 34.656906, Tag: Yes\n",
      "Word: understand, Start: 34.656906, End: 35.0533, Tag: Yes\n",
      "Word: at, Start: 35.0533, End: 35.291134, Tag: No\n",
      "Word: first, Start: 35.291134, End: 35.608246, Tag: Yes\n",
      "Word: but, Start: 36.33771, End: 36.576187, Tag: Yes\n",
      "Word: keep, Start: 36.576187, End: 36.81466, Tag: Yes\n",
      "Word: watching, Start: 36.81466, End: 37.21212, Tag: No\n",
      "Word: you, Start: 37.76856, End: 38.007034, Tag: Yes\n",
      "Word: will, Start: 38.007034, End: 38.245506, Tag: Yes\n",
      "Word: get, Start: 38.245506, End: 38.483982, Tag: Yes\n",
      "Word: better, Start: 38.483982, End: 38.80195, Tag: Yes\n",
      "Word: you, Start: 39.35839, End: 39.596863, Tag: Yes\n",
      "Word: will, Start: 39.596863, End: 39.994324, Tag: Yes\n",
      "Word: improve, Start: 39.994324, End: 40.312286, Tag: Yes\n",
      "Word: let's, Start: 41.107204, End: 41.345676, Tag: No\n",
      "Word: get, Start: 41.345676, End: 41.584152, Tag: Yes\n",
      "Word: started, Start: 41.584152, End: 41.98161, Tag: No\n",
      "\n",
      "Words in unique words list: 60\n",
      "Words not in unique words list: 31\n"
     ]
    }
   ],
   "source": [
    "import json \n",
    "with open(global_transcript_path, 'r') as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "words = data['results']['channels'][0]['alternatives'][0]['words']\n",
    "\n",
    "# Create a list of tuples with word and timestamps\n",
    "parsed_words = [(word_info['word'], word_info['start'], word_info['end']) for word_info in words]\n",
    "\n",
    "# Display the list of words and timestamps\n",
    "in_unique_words = 0\n",
    "not_in_unique_words = 0\n",
    "\n",
    "for word, start, end in parsed_words:\n",
    "    word_lower = word.lower().strip()\n",
    "    if word_lower in unique_words:\n",
    "        tag = \"Yes\"\n",
    "        in_unique_words += 1\n",
    "    else:\n",
    "        tag = \"No\"\n",
    "        not_in_unique_words += 1\n",
    "    print(f\"Word: {word}, Start: {start}, End: {end}, Tag: {tag}\")\n",
    "\n",
    "print(f\"\\nWords in unique words list: {in_unique_words}\")\n",
    "print(f\"Words not in unique words list: {not_in_unique_words}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6eb9e99b-0071-4e5c-a253-1f0ebb73ec4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "  \"new_sentences\": [\n",
    "    \"It is that fundamental belief.\",\n",
    "    \"I am my brother's keeper.\",\n",
    "    \"I am my sister's keeper that makes this country work.\",\n",
    "    \"It's what allows us to pursue our individual dreams and yet still come together as one American family.\",\n",
    "    \"E pluribus unum: out of many, one.\",\n",
    "    \"Now, even as we speak, there are those who are preparing to divide.\",\n",
    "    \"The spin masters, the negative ad peddlers who embrace the politics of anything goes.\",\n",
    "    \"Well, I say to them tonight, there is not a liberal America and a conservative America.\",\n",
    "    \"There is the United States of America.\",\n",
    "    \"There is not a black America and a white America and Latino America and Asian America.\",\n",
    "    \"There's the United States of America.\",\n",
    "    \"The pundits like to slice and dice our country into red states and blue states, red states for Republicans, blue states for Democrats, but I've got news for them too.\",\n",
    "    \"We worship an awesome God in the blue states, and we don't like federal agents poking around in our libraries in the red states.\",\n",
    "    \"We coach little league in the blue states.\",\n",
    "    \"And, yes, we've got some gay friends in the red states.\",\n",
    "    \"There are patriots who oppose the war in Iraq.\",\n",
    "    \"And there are patriots who supported the war in Iraq.\",\n",
    "    \"We are one people, all of us pledging allegiance to the stars and stripes.\",\n",
    "    \"All of us defending the United States of America.\"\n",
    "  ],\n",
    "  \"gloss\": [\n",
    "    [\"believe\"],\n",
    "    [\"me\", \"brother\", \"help\"],\n",
    "    [\"me\", \"sister\", \"help\", \"make\", \"country\", \"work\"],\n",
    "    [\"allow\", \"we\", \"want\", \"dream\", \"but\", \"still\", \"together\", \"one\", \"america\", \"family\"],\n",
    "    [\"many\", \"become\", \"one\"],\n",
    "    [\"now\", \"we\", \"talk\", \"some\", \"people\", \"prepare\", \"divide\"],\n",
    "    [\"people\", \"negative\", \"politics\", \"accept\", \"anything\"],\n",
    "    [\"me\", \"tell\", \"them\", \"tonight\", \"no\", \"liberal\", \"america\", \"conservative\", \"america\"],\n",
    "    [\"have\", \"united\", \"states\", \"america\"],\n",
    "    [\"no\", \"black\", \"america\", \"white\", \"america\", \"latino\", \"america\", \"asia\", \"america\"],\n",
    "    [\"have\", \"united\", \"states\", \"america\"],\n",
    "    [\"people\", \"like\", \"cut\", \"country\", \"red\", \"state\", \"blue\", \"state\", \"red\", \"republican\", \"blue\", \"democrat\", \"but\", \"me\", \"have\", \"news\"],\n",
    "    [\"we\", \"worship\", \"god\", \"blue\", \"state\", \"we\", \"no\", \"like\", \"government\", \"look\", \"library\", \"red\", \"state\"],\n",
    "    [\"we\", \"teach\", \"baseball\", \"blue\", \"state\"],\n",
    "    [\"yes\", \"we\", \"have\", \"gay\", \"friend\", \"red\", \"state\"],\n",
    "    [\"have\", \"patriot\", \"against\", \"war\", \"iraq\"],\n",
    "    [\"have\", \"patriot\", \"support\", \"war\", \"iraq\"],\n",
    "    [\"we\", \"one\", \"people\", \"all\", \"we\", \"promise\", \"flag\"],\n",
    "    [\"all\", \"we\", \"protect\", \"united\", \"states\", \"america\"]\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "94db71e3-303b-4881-958a-29d54e35e8ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['believe']\n",
      "believe\n",
      "['me', 'brother', 'help']\n",
      "me\n",
      "brother\n",
      "help\n",
      "['me', 'sister', 'help', 'make', 'country', 'work']\n",
      "me\n",
      "sister\n",
      "help\n",
      "make\n",
      "country\n",
      "work\n",
      "['allow', 'we', 'want', 'dream', 'but', 'still', 'together', 'one', 'america', 'family']\n",
      "allow\n",
      "we\n",
      "want\n",
      "dream\n",
      "but\n",
      "still\n",
      "together\n",
      "one\n",
      "america\n",
      "family\n",
      "['many', 'become', 'one']\n",
      "many\n",
      "become\n",
      "one\n",
      "['now', 'we', 'talk', 'some', 'people', 'prepare', 'divide']\n",
      "now\n",
      "we\n",
      "talk\n",
      "some\n",
      "people\n",
      "prepare\n",
      "divide\n",
      "['people', 'negative', 'politics', 'accept', 'anything']\n",
      "people\n",
      "negative\n",
      "politics\n",
      "accept\n",
      "anything\n",
      "Token not found: anything\n",
      "['me', 'tell', 'them', 'tonight', 'no', 'liberal', 'america', 'conservative', 'america']\n",
      "me\n",
      "tell\n",
      "them\n",
      "tonight\n",
      "no\n",
      "liberal\n",
      "Token not found: liberal\n",
      "america\n",
      "conservative\n",
      "Token not found: conservative\n",
      "america\n",
      "['have', 'united', 'states', 'america']\n",
      "have\n",
      "united\n",
      "Token not found: united\n",
      "states\n",
      "Token not found: states\n",
      "america\n",
      "['no', 'black', 'america', 'white', 'america', 'latino', 'america', 'asia', 'america']\n",
      "no\n",
      "black\n",
      "america\n",
      "white\n",
      "america\n",
      "latino\n",
      "Token not found: latino\n",
      "america\n",
      "asia\n",
      "america\n",
      "['have', 'united', 'states', 'america']\n",
      "have\n",
      "united\n",
      "Token not found: united\n",
      "states\n",
      "Token not found: states\n",
      "america\n",
      "['people', 'like', 'cut', 'country', 'red', 'state', 'blue', 'state', 'red', 'republican', 'blue', 'democrat', 'but', 'me', 'have', 'news']\n",
      "people\n",
      "like\n",
      "cut\n",
      "country\n",
      "red\n",
      "state\n",
      "Token not found: state\n",
      "blue\n",
      "state\n",
      "Token not found: state\n",
      "red\n",
      "republican\n",
      "Token not found: republican\n",
      "blue\n",
      "democrat\n",
      "but\n",
      "me\n",
      "have\n",
      "news\n",
      "Token not found: news\n",
      "['we', 'worship', 'god', 'blue', 'state', 'we', 'no', 'like', 'government', 'look', 'library', 'red', 'state']\n",
      "we\n",
      "worship\n",
      "Token not found: worship\n",
      "god\n",
      "blue\n",
      "state\n",
      "Token not found: state\n",
      "we\n",
      "no\n",
      "like\n",
      "government\n",
      "look\n",
      "Token not found: look\n",
      "library\n",
      "red\n",
      "state\n",
      "Token not found: state\n",
      "['we', 'teach', 'baseball', 'blue', 'state']\n",
      "we\n",
      "teach\n",
      "baseball\n",
      "blue\n",
      "state\n",
      "Token not found: state\n",
      "['yes', 'we', 'have', 'gay', 'friend', 'red', 'state']\n",
      "yes\n",
      "we\n",
      "have\n",
      "gay\n",
      "friend\n",
      "red\n",
      "state\n",
      "Token not found: state\n",
      "['have', 'patriot', 'against', 'war', 'iraq']\n",
      "have\n",
      "patriot\n",
      "Token not found: patriot\n",
      "against\n",
      "war\n",
      "iraq\n",
      "Token not found: iraq\n",
      "['have', 'patriot', 'support', 'war', 'iraq']\n",
      "have\n",
      "patriot\n",
      "Token not found: patriot\n",
      "support\n",
      "war\n",
      "iraq\n",
      "Token not found: iraq\n",
      "['we', 'one', 'people', 'all', 'we', 'promise', 'flag']\n",
      "we\n",
      "one\n",
      "people\n",
      "all\n",
      "we\n",
      "promise\n",
      "flag\n",
      "['all', 'we', 'protect', 'united', 'states', 'america']\n",
      "all\n",
      "we\n",
      "protect\n",
      "united\n",
      "Token not found: united\n",
      "states\n",
      "Token not found: states\n",
      "america\n",
      "{'liberal', 'state', 'news', 'anything', 'look', 'united', 'latino', 'republican', 'iraq', 'worship', 'conservative', 'states', 'patriot'}\n",
      "{9: 92, 5: 137, 16: 6, 91: 11, 92: 2, 109: 88, 2: 27, 4: 30, 13: 73, 20: 75, 11: 115, 56: 26, 70: 6, 64: 4, 24: 24, 116: 2, 112: 13, 52: 3, 59: 12, 90: 16, 30: 18, 12: 76, 36: 24, 39: 9, 115: 22, 65: 4, 21: 15, 17: 2, 14: 59, 10: 41, 108: 1, 113: 13, 121: 30, 37: 6, 87: 15, 99: 3, 25: 27, 19: 18, 38: 22, 31: 10, 80: 1, 41: 23, 3: 15, 88: 7, 69: 4, 89: 3, 118: 41, 100: 9, 7: 8, 102: 4, 94: 3, 32: 3, 110: 13, 98: 2, 93: 6, 0: 4, 105: 3, 6: 12, 83: 4, 45: 10, 44: 2, 62: 1, 42: 2, 33: 2, 97: 1, 107: 1, 26: 1, 47: 14, 15: 4, 51: 10, 68: 10, 8: 8, 60: 3, 82: 3, 111: 9, 46: 4, 106: 3, 28: 1, 72: 2}\n"
     ]
    }
   ],
   "source": [
    "signer_count = {}\n",
    "tokens_not_found = set()\n",
    "for sentence in data['gloss']:\n",
    "    print(sentence)\n",
    "    sentence_videos = []\n",
    "    for token in sentence:\n",
    "        print(token)\n",
    "        try:\n",
    "            row = df.loc[df['gloss'] == token].iloc[0]\n",
    "        except IndexError:\n",
    "            print(f\"Token not found: {token}\")\n",
    "            tokens_not_found.add(token)\n",
    "            sentence_videos.append([])\n",
    "            continue\n",
    "        video_data = row['instances']\n",
    "        for video in video_data:\n",
    "            if video['signer_id'] not in signer_count:\n",
    "                signer_count[video['signer_id']] = 0\n",
    "            signer_count[video['signer_id']] += 1\n",
    "        sentence_videos.append(video_data)\n",
    "\n",
    "print(tokens_not_found)\n",
    "print(signer_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071cccfa-c480-4426-9197-77888f3072ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba1c0d0-824e-41ba-922f-58859b421dbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76889fa-1141-43d9-9849-bb4839f51f52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316d7946-7ecd-4c99-8c86-cb54185cb8ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ae3dbd-db17-4c73-a121-e4f0e2238b96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c965a87f-8692-4695-9fbd-c1fc79440597",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b28bbe4-d72f-4a16-b2ed-25d33505d2e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4f91b44c-fd35-4efe-bd6e-6cba5c5f262a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  You can now view your Streamlit app in your browser.\n",
      "\n",
      "  Local URL: http://localhost:8502\n",
      "  Network URL: http://192.168.1.109:8502\n",
      "\n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=yJzjyYL8l5Y\n",
      "[youtube] yJzjyYL8l5Y: Downloading webpage\n",
      "[youtube] yJzjyYL8l5Y: Downloading ios player API JSON\n",
      "[youtube] yJzjyYL8l5Y: Downloading tv player API JSON\n",
      "[youtube] yJzjyYL8l5Y: Downloading m3u8 information\n",
      "[info] yJzjyYL8l5Y: Downloading 1 format(s): 243+251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-03 15:43:44.006 Thread 'MainThread': missing ScriptRunContext\n",
      "2024-08-03 15:43:44.008 Thread 'MainThread': missing ScriptRunContext\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[download] yJzjyYL8l5Y.webm has already been downloaded\n",
      "You can now view your Streamlit app in your browser.\n",
      "Local URL: http://localhost:8502\n",
      "Network URL: NgrokTunnel: \"https://a031-107-3-134-29.ngrok-free.app\" -> \"http://localhost:8502\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-03 15:43:44.009 Thread 'MainThread': missing ScriptRunContext\n",
      "2024-08-03 15:43:44.010 Thread 'MainThread': missing ScriptRunContext\n",
      "2024-08-03 15:43:44.012 Thread 'MainThread': missing ScriptRunContext\n",
      "2024-08-03 15:43:44.013 Thread 'MainThread': missing ScriptRunContext\n",
      "2024-08-03 15:43:44.014 Thread 'MainThread': missing ScriptRunContext\n",
      "2024-08-03 15:43:44.015 Thread 'MainThread': missing ScriptRunContext\n",
      "2024-08-03 15:43:44.015 Thread 'MainThread': missing ScriptRunContext\n",
      "2024-08-03 15:43:44.016 Thread 'MainThread': missing ScriptRunContext\n",
      "2024-08-03 15:43:44.017 Thread 'MainThread': missing ScriptRunContext\n",
      "2024-08-03 15:43:44.018 Thread 'MainThread': missing ScriptRunContext\n",
      "2024-08-03 15:43:44.019 Thread 'MainThread': missing ScriptRunContext\n",
      "2024-08-03 15:43:44.020 Thread 'MainThread': missing ScriptRunContext\n",
      "2024-08-03 15:43:44.020 Thread 'MainThread': missing ScriptRunContext\n",
      "2024-08-03 15:43:44.021 Thread 'MainThread': missing ScriptRunContext\n",
      "2024-08-03 15:43:44.021 Thread 'MainThread': missing ScriptRunContext\n",
      "2024-08-03 15:43:44.021 Thread 'MainThread': missing ScriptRunContext\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shutting down...  Stopping...\n",
      "\n",
      "  Stopping...\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import time\n",
    "from pyngrok import ngrok\n",
    "import streamlit as st\n",
    "from streamlit_app import main  # Import the main function from streamlit_app.py\n",
    "\n",
    "# Start the Streamlit app as a subprocess\n",
    "port = 8502\n",
    "streamlit_process = subprocess.Popen([\"streamlit\", \"run\", \"streamlit_app.py\", f\"--server.port={port}\"])\n",
    "\n",
    "# Wait a bit for Streamlit to start\n",
    "time.sleep(5)\n",
    "\n",
    "# Use ngrok to create a public URL\n",
    "public_url = ngrok.connect(port)\n",
    "print(f\"You can now view your Streamlit app in your browser.\")\n",
    "print(f\"Local URL: http://localhost:{port}\")\n",
    "print(f\"Network URL: {public_url}\")\n",
    "\n",
    "# Run the main function in the notebook\n",
    "main()\n",
    "\n",
    "# Keep the notebook running and clean up when interrupted\n",
    "try:\n",
    "    while True:\n",
    "        time.sleep(1)\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Shutting down...\")\n",
    "    streamlit_process.terminate()\n",
    "    ngrok.kill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76993b94-b50e-4a29-b3e3-b3ad2124825b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2ddf1d-cd0b-431b-b4bc-03f91edabc03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62b29f0-56e1-414d-88ee-e6be817207d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9d0c55-f44a-40f3-94c3-d4696236b91b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9377cfbd-5184-4b97-9abc-52077bcf1b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "https://www.youtube.com/watch?v=yJzjyYL8l5Y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
